{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f584c5cb",
      "metadata": {
        "id": "f584c5cb"
      },
      "source": [
        "# Wan2GP on Google Colab\n",
        "\n",
        "Sets up [Wan2GP](https://github.com/deepbeepmeep/Wan2GP) in a fresh GPU-backed Colab session.\n",
        "\n",
        "Run the cells in order to prepare the runtime, install dependencies, and launch the Gradio interface. Click on the link in the output from the last cell to launch the app in your browser.\n",
        "\n",
        "> **Colab VRAM note:** the free tier usually assigns a 15 GB T4 GPU. Most Wan2GP models exceed that budget; the Wan 2.2 TextImage2Video FastWan model works, producing roughly a 5 second 480p clip in about 8 minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77130695",
      "metadata": {
        "id": "77130695"
      },
      "source": [
        "## 1. Confirm the accelerator\n",
        "\n",
        "Choose `Runtime → Change runtime type` and select **GPU** before running anything else.\n",
        "\n",
        "If this cell raises an error, go back to `Runtime → Change runtime type`, pick **GPU** and save.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4039d142",
      "metadata": {
        "id": "4039d142"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.run(['nvidia-smi'], check=True)\n",
        "except Exception as exc:\n",
        "    raise RuntimeError(\n",
        "        'GPU not detected. In Colab, open Runtime → Change runtime type, select GPU (or TPU if GPUs are unavailable), save, then rerun this cell.'\n",
        "    ) from exc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f52fd5",
      "metadata": {
        "id": "56f52fd5"
      },
      "source": [
        "## 2. Configure the workspace path\n",
        "\n",
        "Choose where Wan2GP should be installed. Update `WAN2GP_ROOT` if you prefer a different location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d7ee132",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7ee132",
        "outputId": "b7bb38d3-49c4-45ad-f964-e7385b8d80d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wan2GP will be installed to: /content/Wan2GP\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "WAN2GP_ROOT = Path('/content/Wan2GP').resolve()\n",
        "print(f'Wan2GP will be installed to: {WAN2GP_ROOT}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3594ffa",
      "metadata": {
        "id": "e3594ffa"
      },
      "source": [
        "## 3. Download or update Wan2GP\n",
        "\n",
        "Clone the repository if it is not present yet; otherwise pull the latest changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a3dc4c56",
      "metadata": {
        "id": "a3dc4c56"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "repo_url = 'https://github.com/deepbeepmeep/Wan2GP.git'\n",
        "if WAN2GP_ROOT.exists():\n",
        "    print('Repository already exists. Pulling latest changes...')\n",
        "    subprocess.run(['git', '-C', str(WAN2GP_ROOT), 'pull'], check=True)\n",
        "else:\n",
        "    subprocess.run(['git', 'clone', repo_url, str(WAN2GP_ROOT)], check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ea607f",
      "metadata": {
        "id": "95ea607f"
      },
      "source": [
        "## 4. Install system dependencies\n",
        "\n",
        "Install shared libraries needed for video and audio processing. If you see a warning about skipping an extra repository, it is safe to ignore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ef235d0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef235d0f",
        "outputId": "2e803a2d-fa2e-441f-ae57-c392051f5241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['sudo', 'apt-get', 'install', '-y', '--no-install-recommends', 'ffmpeg', 'libglib2.0-0', 'libgl1', 'libportaudio2'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os, subprocess\n",
        "\n",
        "env = os.environ.copy()\n",
        "env['DEBIAN_FRONTEND'] = 'noninteractive'\n",
        "\n",
        "subprocess.run(['sudo', 'apt-get', 'update', '-qq'], check=True, env=env)\n",
        "subprocess.run([\n",
        "    'sudo', 'apt-get', 'install', '-y', '--no-install-recommends',\n",
        "    'ffmpeg', 'libglib2.0-0', 'libgl1', 'libportaudio2'\n",
        "], check=True, env=env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f619664",
      "metadata": {
        "id": "1f619664"
      },
      "source": [
        "## 5. Install Python dependencies\n",
        "\n",
        "Install PyTorch, xformers and Wan2GP's Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d7093e37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7093e37",
        "outputId": "3ca37db5-20b1-488d-e585-0995ecc57fe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['/usr/bin/python3', '-m', 'pip', 'install', '-r', '/content/Wan2GP/requirements.txt'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os, subprocess, sys\n",
        "\n",
        "env = os.environ.copy()\n",
        "env.setdefault('DEBIAN_FRONTEND', 'noninteractive')\n",
        "\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'], check=True, env=env)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch==2.8.0', 'torchvision', 'torchaudio', '--index-url', 'https://download.pytorch.org/whl/cu128'], check=True, env=env)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"xformers==0.0.32.post2\", \"--index-url\", \"https://download.pytorch.org/whl/cu128\"],\n",
        "               check=True, env=env)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', str(WAN2GP_ROOT / 'requirements.txt')], check=True, env=env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASDZ5Ryi49L-"
      },
      "source": [
        "## 5b. Force a headless matplotlib backend\n",
        "\n",
        "Ensure Wan2GP's preprocessing tools use the headless Agg backend so Step 6 launches cleanly in Colab.\n"
      ],
      "id": "ASDZ5Ryi49L-"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "779d7612",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "779d7612",
        "outputId": "145abfa0-e7c3-46ea-d0e3-41a81655c4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced TkAgg with Agg in interact_tools.py.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Replace the TkAgg backend with the headless Agg backend if present.\n",
        "target = WAN2GP_ROOT / 'preprocessing/matanyone/tools/interact_tools.py'\n",
        "needle = \"matplotlib.use('TkAgg')\"\n",
        "replacement = \"matplotlib.use('Agg')\"\n",
        "\n",
        "if not target.exists():\n",
        "    print(f'Skipping: {target} not found.')\n",
        "else:\n",
        "    text = target.read_text()\n",
        "    if replacement in text:\n",
        "        print('Agg backend already set; no change needed.')\n",
        "    elif needle in text:\n",
        "        target.write_text(text.replace(needle, replacement, 1))\n",
        "        print('Replaced TkAgg with Agg in interact_tools.py.')\n",
        "    else:\n",
        "        print('Backend call not found; no change made.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7d6487",
      "metadata": {
        "id": "5e7d6487"
      },
      "source": [
        "## 6. Launch Wan2GP\n",
        "\n",
        "Run the Gradio interface. You will find the gradio link in the output. Click on the link to access the UI. Keep the cell running to stay connected; stop it with the square **Stop** button when you are finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb423194",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb423194",
        "outputId": "798ae68a-35d7-4409-df5b-b5a53a620b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Wan2GP…\n",
            "2026-01-31 09:49:27.883842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769852968.130776    2957 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769852968.198518    2957 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769852968.691636    2957 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769852968.691672    2957 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769852968.691675    2957 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769852968.691677    2957 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-31 09:49:28.740297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[keepalive] Notebook cell still running…\n",
            "/content/Wan2GP/models/ltx_video/schedulers/rf.py:323: SyntaxWarning: invalid escape sequence '\\D'\n",
            "  z_{t_1} = z_t - \\Delta_t * v\n",
            "Switching to FP16 models when possible as GPU architecture doesn't support optimed BF16 Kernels\n",
            "Switching to FP16 models when possible as GPU architecture doesn't support optimed BF16 Kernels\n",
            "[keepalive] Notebook cell still running…\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://210291afac9c0ba1c8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "Loading Model 'ckpts/ltx-2-19b-distilled_Q4_K_M.gguf' ...\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "Loading Text Encoder 'ckpts/gemma-3-12b-it-qat-q4_0-unquantized/gemma-3-12b-it-qat-q4_0-unquantized_quanto_bf16_int8.safetensors' ...\n",
            "\u001b[1m\u001b[95m************ Memory Management for the GPU Poor (mmgp 3.7.2) by DeepBeepMeep ************\u001b[0m\u001b[0m\n",
            "Hooked to model 'transformer' (X0Model)\n",
            "Async loading plan for model 'transformer' : base size of 443.19 MB will be preloaded with a 237.48 MB async circular shuttle\n",
            "Hooked to model 'text_encoder' (Gemma3ForCausalLM)\n",
            "Async loading plan for model 'text_encoder' : base size of 1920.48 MB will be preloaded with a 213.87 MB async circular shuttle\n",
            "Hooked to model 'text_embedding_projection' (GemmaFeaturesExtractorProjLinear)\n",
            "Hooked to model 'text_embeddings_connector' (GemmaTextEmbeddingsConnectorModel)\n",
            "Hooked to model 'vae' (VideoDecoder)\n",
            "Async loading plan for model 'vae' : base size of 7.07 MB will be preloaded with a 540.02 MB async circular shuttle\n",
            "Hooked to model 'video_encoder' (VideoEncoder)\n",
            "Async loading plan for model 'video_encoder' : base size of 13.92 MB will be preloaded with a 864.02 MB async circular shuttle\n",
            "Hooked to model 'audio_encoder' (AudioEncoder)\n",
            "Hooked to model 'audio_decoder' (AudioDecoder)\n",
            "Hooked to model 'vocoder' (Vocoder)\n",
            "Hooked to model 'spatial_upsampler' (LatentUpsampler)\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "  0%|          | 0/8 [00:00<?, ?steps/s]\n",
            "[keepalive] Notebook cell still running…\n",
            " 12%|█▎        | 1/8 [01:16<08:52, 76.02s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            " 25%|██▌       | 2/8 [02:27<07:21, 73.55s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            " 38%|███▊      | 3/8 [03:39<06:03, 72.77s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            " 50%|█████     | 4/8 [04:51<04:50, 72.52s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            " 62%|██████▎   | 5/8 [06:03<03:36, 72.29s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            " 75%|███████▌  | 6/8 [07:15<02:24, 72.05s/steps]\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            " 88%|████████▊ | 7/8 [08:26<01:11, 71.86s/steps]\n",
            "100%|██████████| 8/8 [09:38<00:00, 71.76s/steps]\n",
            "100%|██████████| 8/8 [09:38<00:00, 72.29s/steps]\n",
            "\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n",
            "  0%|          | 0/3 [00:00<?, ?steps/s]\n",
            "[keepalive] Notebook cell still running…\n",
            "[keepalive] Notebook cell still running…\n"
          ]
        }
      ],
      "source": [
        "import os, subprocess, sys, threading, time\n",
        "\n",
        "env = os.environ.copy()\n",
        "env.setdefault('WAN_CACHE_DIR', str(WAN2GP_ROOT / 'models'))\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    '-u',\n",
        "    'wgp.py',\n",
        "    '--listen',\n",
        "    '--server-port', '7860',\n",
        "    '--share',\n",
        "    '--profile', '5',\n",
        "]\n",
        "print('Launching Wan2GP…')\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    cwd=str(WAN2GP_ROOT),\n",
        "    env=env,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        ")\n",
        "stop_event = threading.Event()\n",
        "\n",
        "def keepalive():\n",
        "    while not stop_event.is_set():\n",
        "        time.sleep(45)\n",
        "        if stop_event.is_set():\n",
        "            break\n",
        "        print('[keepalive] Notebook cell still running…')\n",
        "\n",
        "keepalive_thread = threading.Thread(target=keepalive, daemon=True)\n",
        "keepalive_thread.start()\n",
        "\n",
        "try:\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if not line:\n",
        "            break\n",
        "        print(line, end='')\n",
        "except KeyboardInterrupt:\n",
        "    print('Stopping Wan2GP…')\n",
        "    process.terminate()\n",
        "finally:\n",
        "    stop_event.set()\n",
        "    process.wait()\n",
        "    keepalive_thread.join(timeout=1)\n",
        "    print(f'Wan2GP stopped (return code: {process.returncode}).')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wan2GP on Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}